{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6082fccf-c1d4-45b3-8ae7-4b3029b51da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved into the data folder\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bcsc_paths = [\n",
    "    \"../data/bcsc_risk_factors_summarized1_092020.csv\",\n",
    "    \"../data/bcsc_risk_factors_summarized2_092020.csv\",\n",
    "    \"../data/bcsc_risk_factors_summarized3_092020.csv\",\n",
    "]\n",
    "df_list = []\n",
    "for path in bcsc_paths:\n",
    "    bcsc = pd.read_csv(path)\n",
    "    df_list.append(bcsc)\n",
    "bcsc_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "bcsc_df_clean = (bcsc_df[~(bcsc_df.iloc[:, 2:12] == 9).any(axis=1)].reset_index(drop=True))\n",
    "bcsc_df_clean.to_csv(\"../data/bcsc_concatenated_no_9.csv\", index=False)\n",
    "print(f\"saved into the data folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512aee58-f27b-4494-8bd8-8072e534e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab9bfe6-0b7f-497e-b53d-3bea0b1996f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (276051, 12), Test shape: (69013, 12)\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best hyperparameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.6}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.86     58427\n",
      "           1       0.42      0.88      0.57     10586\n",
      "\n",
      "    accuracy                           0.79     69013\n",
      "   macro avg       0.69      0.83      0.71     69013\n",
      "weighted avg       0.89      0.79      0.82     69013\n",
      "\n",
      "Test ROC AUC: 0.9079809613266547\n",
      "\n",
      "Confusion Matrix:\n",
      " [[45420 13007]\n",
      " [ 1290  9296]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "import joblib\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/bcsc_concatenated_no_9.csv\")\n",
    "X = df.drop(columns=\"breast_cancer_history\")\n",
    "y = df[\"breast_cancer_history\"]\n",
    "\n",
    "# Split off a fixed 20% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,     \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Training shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# Compute imbalance weight on the full train set\n",
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# Hyperparameter search on training set only\n",
    "base_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42\n",
    ")\n",
    "param_dist = {\n",
    "    \"n_estimators\":     [100, 300, 500],\n",
    "    \"max_depth\":        [3, 5, 7],\n",
    "    \"learning_rate\":    [0.01, 0.05, 0.1],\n",
    "    \"subsample\":        [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\":            [0, 1, 5],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=base_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"recall\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", search.best_params_)\n",
    "\n",
    "# Retrain best estimator on the full training set\n",
    "best = search.best_estimator_\n",
    "best.set_params(scale_pos_weight=scale_pos_weight)\n",
    "best.fit(X_train, y_train)\n",
    "\n",
    "# Final evaluation on the test set\n",
    "y_prob = best.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=best.classes_)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c6d1f3-31c6-4037-99cb-b8bf1b1e9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (276051, 12), Test shape: (69013, 12)\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vetdd\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vetdd\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:56:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\vetdd\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:56:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for recall: 0.10 → recall = 1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     58427\n",
      "           1       0.15      1.00      0.27     10586\n",
      "\n",
      "    accuracy                           0.15     69013\n",
      "   macro avg       0.08      0.50      0.13     69013\n",
      "weighted avg       0.02      0.15      0.04     69013\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[    0 58427]\n",
      " [    0 10586]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vetdd\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vetdd\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vetdd\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, recall_score\n",
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "import joblib\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/bcsc_concatenated_no_9.csv\")\n",
    "X = df.drop(columns=\"breast_cancer_history\")\n",
    "y = df[\"breast_cancer_history\"]\n",
    "\n",
    "# Split off a fixed 20% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,     \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Training shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        random_state=42,\n",
    "    )),\n",
    "])\n",
    "param_dist = {\n",
    "    \"clf__n_estimators\":     [100, 300, 500, 800],\n",
    "    \"clf__max_depth\":        [3, 5, 7],\n",
    "    \"clf__learning_rate\":    [0.01, 0.05, 0.1],\n",
    "    \"clf__subsample\":        [0.6, 0.8, 1.0],\n",
    "    \"clf__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"clf__gamma\":            [0, 1, 5]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=\"recall\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,   n_jobs=-1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# 3) Retrain with early stopping\n",
    "best_pipe = search.best_estimator_\n",
    "best_pipe.named_steps['clf'].set_params(\n",
    "    **{\"scale_pos_weight\":(neg/pos)}\n",
    ")\n",
    "best_pipe.named_steps['clf'].fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 4) Threshold tuning\n",
    "probs = best_pipe.predict_proba(X_test)[:,1]\n",
    "best_thresh, best_recall = 0.5, 0\n",
    "for thresh in np.linspace(0.1, 0.9, 81):\n",
    "    preds = (probs >= thresh).astype(int)\n",
    "    r = recall_score(y_test, preds)\n",
    "    if r > best_recall:\n",
    "        best_recall, best_thresh = r, thresh\n",
    "\n",
    "print(f\"Best threshold for recall: {best_thresh:.2f} → recall = {best_recall:.3f}\")\n",
    "\n",
    "# Then use it:\n",
    "y_pred = (probs >= best_thresh).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=best.classes_)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24500c2c-362a-4275-bbf4-fdca9de655c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (276051, 12), Test shape: (69013, 12)\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best hyperparameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.6}\n",
      "Best threshold by G-mean: 0.527 → G-mean = 0.828\n",
      "\n",
      "=== Threshold: G-mean (0.527) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.86     58427\n",
      "           1       0.42      0.88      0.57     10586\n",
      "\n",
      "    accuracy                           0.79     69013\n",
      "   macro avg       0.69      0.83      0.71     69013\n",
      "weighted avg       0.89      0.79      0.82     69013\n",
      "\n",
      "Confusion Matrix:\n",
      " [[45420 13007]\n",
      " [ 1290  9296]]\n",
      "\n",
      "Test ROC AUC: 0.9079809613266547\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "import joblib\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/bcsc_concatenated_no_9.csv\")\n",
    "X = df.drop(columns=\"breast_cancer_history\")\n",
    "y = df[\"breast_cancer_history\"]\n",
    "\n",
    "# Split off a fixed 20% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,     \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Training shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# Compute imbalance weight on the full train set\n",
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos\n",
    "# Hyperparameter search on training set only\n",
    "base_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42\n",
    ")\n",
    "param_dist = {\n",
    "    \"n_estimators\":     [100, 300, 500],\n",
    "    \"max_depth\":        [3, 5, 7],\n",
    "    \"learning_rate\":    [0.01, 0.05, 0.1],\n",
    "    \"subsample\":        [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\":            [0, 1, 5],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=base_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"recall\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", search.best_params_)\n",
    "\n",
    "# Retrain best estimator on the full training set\n",
    "best = search.best_estimator_\n",
    "best.set_params(scale_pos_weight=scale_pos_weight)\n",
    "best.fit(X_train, y_train)\n",
    "# Final evaluation on the test set\n",
    "y_prob = best.predict_proba(X_test)[:, 1]\n",
    "# Compute G-mean for each ROC threshold\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "best_idx = np.argmax(gmeans)\n",
    "best_thresh_gmean = thresholds[best_idx]\n",
    "best_gmean = gmeans[best_idx]\n",
    "\n",
    "print(f\"Best threshold by G-mean: {best_thresh_gmean:.3f} → G-mean = {best_gmean:.3f}\")\n",
    "\n",
    "# Compare performance at default (0.5) vs. G-mean threshold\n",
    "\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "print(f\"\\n=== Threshold: {label} ({thresh:.3f}) ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=best.classes_)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# 3) Also print overall ROC AUC\n",
    "print(\"\\nTest ROC AUC:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ec74c-acb2-4646-b3f0-eeedf7ba7c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
